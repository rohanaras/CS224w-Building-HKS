{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seattle Heat Kernel Signature + Persistence Based Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "from heat_kernel_func import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load city data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "luComm = pd.read_csv('../seattle/data/luComm_utm.csv')\n",
    "print('Number of buildings:', len(luComm.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Basemap(\n",
    "        projection='merc',\n",
    "        llcrnrlon=min(luComm['lon']) - .07,\n",
    "        llcrnrlat=min(luComm['lat']) - .01,\n",
    "        urcrnrlon=max(luComm['lon']) + .07,\n",
    "        urcrnrlat=max(luComm['lat']) + .01,\n",
    "        lat_ts=0,\n",
    "        resolution='h',\n",
    "        suppress_ticks=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding $k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_neighbors(points, weighted=True, k=3):\n",
    "    '''\n",
    "    weights are distance\n",
    "    returns a weighted edgelist\n",
    "    '''\n",
    "    num_points = points.shape[0]\n",
    "    \n",
    "    # expanded out form of distance formula\n",
    "    squared = (points ** 2).sum(axis=1, keepdims=True)\n",
    "    mixed = points @ points.T\n",
    "    dists = np.sqrt(squared + squared.T - (2 * mixed))\n",
    "\n",
    "    closest_idx = np.argsort(dists, axis=1)[:, 1:(k + 1)]\n",
    "    \n",
    "    edge_list = []\n",
    "    for i in range(num_points): # this can probably be parallelized\n",
    "        cdists = dists[i, closest_idx[i]]\n",
    "        if weighted:\n",
    "            edge_list.extend([(i, j, cdists[k]) \n",
    "                              for k, j in enumerate(closest_idx[i])])\n",
    "        else:\n",
    "            edge_list.extend([(i, j, 1) \n",
    "                              for k, j in enumerate(closest_idx[i])])\n",
    "\n",
    "    \n",
    "    del dists\n",
    "    del closest_idx\n",
    "    \n",
    "    return edge_list\n",
    "\n",
    "weighted_edge_list = k_neighbors(luComm[['utm10_x', 'utm10_y']].values, k=14)\n",
    "weighted_G = nx.Graph()\n",
    "weighted_G.add_weighted_edges_from(weighted_edge_list)\n",
    "components = nx.number_connected_components(weighted_G)\n",
    "print('Number of connected components:', components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20), dpi=150)\n",
    "m.readshapefile('../seattle/data/Council_Districts/Council_Districts', 'Council_Districts.shp')\n",
    "positions = {i: m(pair[1], pair[2]) \n",
    "             for i, pair in enumerate(luComm[['lon', 'lat']].itertuples())}\n",
    "nx.draw_networkx(weighted_G, positions, node_size=1, with_labels=False, alpha=.7, width=.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $t$ threshold\n",
    "\n",
    "After a certain $t$ value, the number of clusters when $\\tau = 0$ increases sharply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ts = [1e-6, 1e-4, 1e-2, 1e0, 1e2, 1e4, 1e6, 1e8, 1e10]\n",
    "ts = list(np.logspace(-3, 4, num=21))\n",
    "weighted_hks_dict = {}\n",
    "weighted_hks_dict = hks_s(weighted_G, ts, list(weighted_G.nodes()), verbose=True, k=2000,\n",
    "                          eigen_save_loc='eigen_saves/weighted_seattle_knn_norm')\n",
    "def get_num_clusters(G, hks_dict, t):\n",
    "    #_,PD_points = persistence_diagram(G, f=hks_dict[t])\n",
    "    PD_points = {}\n",
    "    C,_ = persistence_diagram(G, f=hks_dict[t], tau=0)\n",
    "    return len(PD_points.keys()), len(set(get_root(node, C) for node in C))\n",
    "num_clusters = []\n",
    "c_set_size = []\n",
    "for t in ts:\n",
    "    points, cpoints = get_num_clusters(weighted_G, weighted_hks_dict, t=t)\n",
    "    num_clusters.append(points)\n",
    "    c_set_size.append(cpoints)\n",
    "plt.figure()\n",
    "#plt.plot(ts, num_clusters)\n",
    "plt.plot(ts, c_set_size, linestyle='-')\n",
    "plt.xlabel('Time (t) value')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Total number of clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "#plt.plot(ts, num_clusters)\n",
    "plt.plot(ts[:-1], c_set_size[:-1], linestyle='-')\n",
    "plt.xlabel('Time (t) value')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Total number of clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c_set_size)\n",
    "print(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring how different values of $t$ affect clustering with $\\tau=0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hks_s' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-be1f59105925>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPD_points\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10e-300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10e-10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.37\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m weighted_hks_dict = hks_s(weighted_G, ts, list(weighted_G.nodes()), verbose=True, k=2000,\n\u001b[0m\u001b[1;32m     15\u001b[0m                           eigen_save_loc='eigen_saves/weighted_seattle_knn_norm')\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hks_s' is not defined"
     ]
    }
   ],
   "source": [
    "def explore_components(G, hks_dict, t, tau):\n",
    "    _, PD_points = persistence_diagram(G, f=hks_dict[t])\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.title('Persistence Diagram (t = ' + str(t) + ', tau = ' + str(tau) + ')')\n",
    "    plot_PD(PD_points, tau=tau)\n",
    "    plt.show()\n",
    "    C, _ = persistence_diagram(G, tau=tau, f=hks_dict[t])\n",
    "    plt.figure(figsize=(20, 20), dpi=150)\n",
    "    plt.title((tau, t, len(C)))\n",
    "    m.readshapefile('../seattle/data/Council_Districts/Council_Districts', 'Council_Districts.shp')\n",
    "    plot_segments(G, C, positions, node_size=10, width=.15, cutoff=2)\n",
    "    return len(PD_points.keys())\n",
    "ts = [10e-300, 10e-10, 0.37]\n",
    "weighted_hks_dict = hks_s(weighted_G, ts, list(weighted_G.nodes()), verbose=True, k=2000,\n",
    "                          eigen_save_loc='eigen_saves/weighted_seattle_knn_norm')\n",
    "for t in ts:\n",
    "    explore_components(weighted_G, weighted_hks_dict, t, tau=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring how clusters persist as we increase $\\tau$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "taus = [0.01, 0.1, 0.5]\n",
    "for tau in taus:\n",
    "    explore_components(weighted_G, weighted_hks_dict, t=1e-9, tau=tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_sizes(C):\n",
    "    from collections import defaultdict\n",
    "    counter = defaultdict(int)\n",
    "    for node in C:\n",
    "        counter[get_root(node, C)] += 1\n",
    "    return counter\n",
    "\n",
    "bwah = []\n",
    "for t in ts:\n",
    "    C, _ = persistence_diagram(weighted_G, tau=0, f=weighted_hks_dict[t])\n",
    "    gcs = get_cluster_sizes(C)\n",
    "    bwah.append(sum(gcs.values()) / len(gcs.values()))\n",
    "plt.plot(ts, bwah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mainEnv",
   "language": "python",
   "name": "mainenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
